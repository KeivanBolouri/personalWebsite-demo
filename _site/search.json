[
  {
    "objectID": "projects_files/Courses.html#coursework-completed-and-in-progress",
    "href": "projects_files/Courses.html#coursework-completed-and-in-progress",
    "title": "Relevant Academic Coursework",
    "section": "Coursework Completed and In-Progress",
    "text": "Coursework Completed and In-Progress\n\nUpper Division and Graduate-Level Mathematics & Statistics Courses\n\n\n\n\n\n\n\n\n\n\nNo.\nCourse (Number & Title)\nTerm\nTextbook Ref\n\n\n\n\n1\nMATH 115A – Linear Algebra\nFall 2024\n[5]\n\n\n2\nSTATS 100A – Introduction to Probability\nFall 2024\n[25], [26]\n\n\n3\nMATH 151A – Applied Numerical Methods\nWinter 2025\n[7]\n\n\n4\nSTATS 100B – Mathematical Statistics\nWinter 2025\n[8]\n\n\n5\nSTATS 101A – Data Analysis & Regression\nWinter 2025\n[9], [10]\n\n\n6\nSTATS 100C – Linear Models\nSpring 2025\n[11], [31]\n\n\n7\nSTATS 101B – Design & Analysis of Experiments\nSpring 2025\n[12]\n\n\n8\nSTATS 102A – Intro to Computational Statistics (R)\nSummer 2025\n[21], [22], [23], [24]\n\n\n9\nMATH 164 – Optimization\nFall 2025\n[13]\n\n\n10\nSTATS 101C – Statistical Models & Data Mining\nFall 2025\n[14]\n\n\n11\nSTATS 102C – Monte Carlo Methods\nFall 2025\n[15]\n\n\n12\nMATH 156 – Machine Learning\nWinter 2026\n[16]\n\n\n13\nMATH 171 – Stochastic Processes\nWinter 2026\n[30]\n\n\n14\nSTATS 102B – Computation & Optimization for Statistics\nSpring 2026\n[18]\n\n\n15\nMATH 182 – Algorithms\nSpring 2026\n[29]"
  },
  {
    "objectID": "projects_files/Courses.html#lower-division-mathematics-statistics-courses",
    "href": "projects_files/Courses.html#lower-division-mathematics-statistics-courses",
    "title": "Relevant Academic Coursework",
    "section": "Lower Division Mathematics & Statistics Courses",
    "text": "Lower Division Mathematics & Statistics Courses\n\n\n\n\n\n\n\n\n\n\nNo.\nCourse (Number & Title)\nTerm\nTextbook Ref\n\n\n\n\n1\nMATH-227 – Statistics\nWinter 2022\n[27]\n\n\n2\nMATH-229 – Statistics for Data Science\nSummer 2024\n[28]\n\n\n3\nMATH 265 – Calculus I\nWinter 2022\n[1]\n\n\n4\nMATH 266 – Calculus II\nSpring 2022\n[1]\n\n\n5\nMATH 267 – Calculus III\nFall 2022\n[1]\n\n\n6\nMATH 270 – Linear Algebra\nFall 2022\n[2]\n\n\n7\nMATH 272 – Methods of Discrete Mathematics\nFall 2023\n[3]\n\n\n8\nMATH 275 – Ordinary Differential Equations\nSpring 2023\n[4]\n\n\n\n\n\n\n\n\n\n\nNoteShow Textbook References\n\n\n\n\n\nReferences\n[1] Stewart, James. Calculus: Early Transcendentals. 8th ed. Cengage, 2015.\n[2] Larson, Ron. Elementary Linear Algebra. 8th ed. Cengage, 2017.\n[3] Epp, Susanna S. Discrete Mathematics with Applications. 5th ed. Cengage, 2019.\n[4] Zill, Dennis G. A First Course in Differential Equations with Modeling Applications. 11th ed. Cengage, 2018.\n[5] Friedberg, Stephen H., Arnold J. Insel, and Lawrence E. Spence. Linear Algebra. 5th ed. Pearson, 2024.\n[6] Ross, Sheldon M. A First Course in Probability. 10th ed. Pearson, 2019.\n[7] Burden, Richard L., J. Douglas Faires, and Annette M. Burden. Numerical Analysis. 10th ed. Cengage, 2015.\n[8] Rice, John A. Mathematical Statistics and Data Analysis. 3rd ed. Cengage, 2006.\n[9] Sheather, Simon J. A Modern Approach to Regression with R. Springer, 2009.\n[10] Kutner, Michael H., et al. Applied Linear Statistical Models. 5th ed. McGraw-Hill, 2005.\n[11] Abraham, B., and J. Ledolter. Introduction to Regression Modeling. Duxbury, 2006.\n[12] Montgomery, Douglas C. Design and Analysis of Experiments. 9th ed. Wiley, 2017.\n[13] Boyd, Stephen, and Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\n[14] James, Gareth, et al. An Introduction to Statistical Learning with R. 2nd ed., Springer, 2021.\n[15] Robert, Christian P., and George Casella. Introducing Monte Carlo Methods with R. Springer, 2010.\n[16] Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.\n[17] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[18] Zhou, Qing. Course Notes for STATS 102B. UCLA.\n[19] Isaaks, Edward H., and R. Mohan Srivastava. An Introduction to Applied Geostatistics. Oxford UP, 1989.\n[20] UCLA Statistics 100C course handouts.\nhttp://www.stat.ucla.edu/~nchristo/statistics100C/\n[21] Wickham, Hadley. Advanced R. 2nd ed. Chapman & Hall/CRC, 2019.\n[22] Jones, O., R. Maillardet, and A. Robinson. Introduction to Scientific Programming and Simulation Using R. CRC Press, 2009.\n[23] Chang, Winston. R Graphics Cookbook. O’Reilly, 2012.\n[24] Zieffler, Andrew, et al. Comparing Groups Using R. Wiley, 2011.\n[25] DeGroot, Morris H., and Mark J. Schervish. Probability and Statistics. 4th ed. Pearson, 2012.\n[26] Hogg, Robert V., et al. Probability and Statistical Inference. 10th ed. Pearson, 2019.\n[27] Illowsky, Barbara, and Susan Dean. Introductory Statistics. 2nd ed. OpenStax, 2022.\n[28] Adhikari, Ani, et al. Computational and Inferential Thinking. 2nd ed., 2022.\n[29] Kleinberg, Jon, and Éva Tardos. Algorithm Design. Addison-Wesley.\n[30] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[31] UCLA Statistics 100C handouts."
  },
  {
    "objectID": "projects_files/Courses.html#references",
    "href": "projects_files/Courses.html#references",
    "title": "Relevant Academic Coursework",
    "section": "References",
    "text": "References\n[1] Stewart, James. Calculus: Early Transcendentals. 8th ed. Cengage, 2015.\n[2] Larson, Ron. Elementary Linear Algebra. 8th ed. Cengage, 2017.\n[3] Epp, Susanna S. Discrete Mathematics with Applications. 5th ed. Cengage, 2019.\n[4] Zill, Dennis G. A First Course in Differential Equations with Modeling Applications. 11th ed. Cengage, 2018.\n[5] Friedberg, Stephen H., Arnold J. Insel, and Lawrence E. Spence. Linear Algebra. 5th ed. Pearson, 2024.\n[6] Ross, Sheldon M. A First Course in Probability. 10th ed. Pearson, 2019.\n[7] Burden, Richard L., J. Douglas Faires, and Annette M. Burden. Numerical Analysis. 10th ed. Cengage, 2015.\n[8] Rice, John A. Mathematical Statistics and Data Analysis. 3rd ed. Cengage, 2006.\n[9] Sheather, Simon J. A Modern Approach to Regression with R. Springer, 2009.\n[10] Kutner, Michael H., et al. Applied Linear Statistical Models. 5th ed. McGraw-Hill, 2005.\n[11] Abraham, B., and J. Ledolter. Introduction to Regression Modeling. Duxbury, 2006.\n[12] Montgomery, Douglas C. Design and Analysis of Experiments. 9th ed. Wiley, 2017.\n[13] Boyd, Stephen, and Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\n[14] James, Gareth, et al. An Introduction to Statistical Learning with R. 2nd ed., Springer, 2021.\n[15] Robert, Christian P., and George Casella. Introducing Monte Carlo Methods with R. Springer, 2010.\n[16] Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.\n[17] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[18] Zhou, Qing. Course Notes for STATS 102B. UCLA.\n[19] Isaaks, Edward H., and R. Mohan Srivastava. An Introduction to Applied Geostatistics. Oxford UP, 1989.\n[20] UCLA Statistics 100C course handouts.\nhttp://www.stat.ucla.edu/~nchristo/statistics100C/\n[21] Wickham, Hadley. Advanced R. 2nd ed. Chapman & Hall/CRC, 2019.\n[22] Jones, O., R. Maillardet, and A. Robinson. Introduction to Scientific Programming and Simulation Using R. CRC Press, 2009.\n[23] Chang, Winston. R Graphics Cookbook. O’Reilly, 2012.\n[24] Zieffler, Andrew, et al. Comparing Groups Using R. Wiley, 2011.\n[25] DeGroot, Morris H., and Mark J. Schervish. Probability and Statistics. 4th ed. Pearson, 2012.\n[26] Hogg, Robert V., et al. Probability and Statistical Inference. 10th ed. Pearson, 2019.\n[27] Illowsky, Barbara, and Susan Dean. Introductory Statistics. 2nd ed. OpenStax, 2022.\n[28] Adhikari, Ani, et al. Computational and Inferential Thinking. 2nd ed., 2022.\n[29] Kleinberg, Jon, and Éva Tardos. Algorithm Design. Addison-Wesley.\n[30] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[31] UCLA Statistics 100C handouts."
  },
  {
    "objectID": "Projects/stat140/Stat140.html#statistical-methods",
    "href": "Projects/stat140/Stat140.html#statistical-methods",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Statistical Methods",
    "text": "Statistical Methods"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#hypothesis-tests",
    "href": "Projects/stat140/Stat140.html#hypothesis-tests",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Hypothesis Tests",
    "text": "Hypothesis Tests\n\nHypothesis 1: Civilian Harm Difference\n\\[\n\\begin{aligned}\nH_{0}: &\\ \\text{Drone strikes have the same civilian impact in Somalia and Yemen.} \\\\\nH_{1}: &\\ \\text{Drone strikes have different civilian impacts across the two regions.}\n\\end{aligned}\n\\]\nTo test whether Somalia and Yemen differ in civilian casualty rates, we estimate:\n\n\n\nVariable Definitions\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nCivilian casualties\nNumber of civilians reported killed in the strike (outcome variable).\n\n\nRegion\nCountry where the strike occurred (Somalia or Yemen).\n\n\nDrone\nIndicates whether the strike was carried out by a drone (1 = drone).\n\n\nUS confirmed\nWhether the strike was officially confirmed by the U.S. government.\n\n\nMinimum strikes\nMinimum number of strike events associated with the record.\n\n\nTotal killed\nMinimum number of total fatalities (civilians + militants).\n\n\n\n\n\n\n\n\n\n\nHypothesis 2: Drone Effectiveness Across Countries\n\\[\n\\begin{aligned}\nH_{0}: &\\ \\text{Drone use affects civilian casualties in the same way in both Somalia and Yemen.} \\\\\nH_{1}: &\\ \\text{Drone use affects civilian casualties differently across Somalia and Yemen.}\n\\end{aligned}\n\\]\nTo evaluate whether drones behave differently across countries, we added an interaction term (drone × region).\n\n\n\n\n\nHypothesis 3: Reporting Uncertainty Differenc\n\\[\n\\begin{aligned}\nH_{0}: &\\ \\text{Reporting uncertainty does not differ between Somalia and Yemen.} \\\\\nH_{1}: &\\ \\text{Reporting uncertainty differs between Somalia and Yemen.}\n\\end{aligned}\n\\]\n\nTo assess whether casualty reporting uncertainty differs between regions, we model the uncertainty metric. We modeled casualty reporting uncertainty (defined as max_killed - min_killed) region and strike characteristics as predictors.\n\\[\n\\text{Uncertainty in casualties} =\n\\text{Maximum killed} - \\text{Minimum killed}\n\\]"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#test-for-hypothesis-2",
    "href": "Projects/stat140/Stat140.html#test-for-hypothesis-2",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Test for Hypothesis 2",
    "text": "Test for Hypothesis 2"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#test-for-hypothesis-3",
    "href": "Projects/stat140/Stat140.html#test-for-hypothesis-3",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Test for Hypothesis 3",
    "text": "Test for Hypothesis 3\n\n##################################\n## Hypothesis 3: Reporting Uncertainty ##\n##################################\n# H0: The level of uncertainty in casualty reporting does not differ between Somalia and Yemen.\n# H1: It does differ.\n# Outcome: uncertainty_killed\n\nmodel_h3 &lt;- glm.nb(\n  uncertainty_killed ~ region + drone + us_confirmed + min_strikes,\n  data = combined_model\n)\n\nsummary(model_h3)\n\n\nCall:\nglm.nb(formula = uncertainty_killed ~ region + drone + us_confirmed + \n    min_strikes, data = combined_model, init.theta = 0.2157180244, \n    link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.64763    0.30943   2.093  0.03635 * \nregionYemen  -0.16294    0.26446  -0.616  0.53781   \ndrone         0.61827    0.24966   2.476  0.01327 * \nus_confirmed -0.69343    0.25255  -2.746  0.00604 **\nmin_strikes   0.08520    0.05284   1.612  0.10687   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.2157) family taken to be 1)\n\n    Null deviance: 400.69  on 513  degrees of freedom\nResidual deviance: 385.48  on 509  degrees of freedom\nAIC: 1571.1\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.2157 \n          Std. Err.:  0.0218 \n\n 2 x log-likelihood:  -1559.1480 \n\ntidy(model_h3, exponentiate = TRUE, conf.int = TRUE)\n\n# A tibble: 5 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     1.91     0.309      2.09  0.0363     1.13      3.34 \n2 regionYemen     0.850    0.264     -0.616 0.538      0.536     1.33 \n3 drone           1.86     0.250      2.48  0.0133     1.18      2.91 \n4 us_confirmed    0.500    0.253     -2.75  0.00604    0.305     0.793\n5 min_strikes     1.09     0.0528     1.61  0.107      0.990     1.28 \n\n###############################################\n## 5. Optional: quick descriptive checks\n###############################################\n\n# Mean civilian casualties by region & drone status\ncombined_model %&gt;%\n  group_by(region, drone) %&gt;%\n  summarise(\n    mean_civilian_casualties = mean(civilian_casualties, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n\n# A tibble: 4 × 4\n  region  drone mean_civilian_casualties     n\n  &lt;fct&gt;   &lt;int&gt;                    &lt;dbl&gt; &lt;int&gt;\n1 Somalia     0                   0.0753   146\n2 Somalia     1                   0.114     44\n3 Yemen       0                   1.38      76\n4 Yemen       1                   0.411    248\n\n# Mean uncertainty by region\ncombined_model %&gt;%\n  group_by(region) %&gt;%\n  summarise(\n    mean_uncertainty = mean(uncertainty_killed, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n\n# A tibble: 2 × 3\n  region  mean_uncertainty     n\n  &lt;fct&gt;              &lt;dbl&gt; &lt;int&gt;\n1 Somalia             1.56   190\n2 Yemen               1.84   324\n\n\n\nResult for Hypothesis 3: Reporting Uncertainty\nReporting uncertainty does not differ between regions (Yemen coef = −0.16, p = 0.538).\nHowever, drone strikes show higher uncertainty (coef = 0.62, IRR = 1.86, p = 0.013), while confirmed U.S. strikes show lower uncertainty (coef = −0.69, IRR = 0.50, p = 0.006).\nConclusion: No regional difference in uncertainty → H3 not supported, though uncertainty varies by strike type."
  },
  {
    "objectID": "Projects/stat140/Stat140.html#visualizations",
    "href": "Projects/stat140/Stat140.html#visualizations",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Visualizations",
    "text": "Visualizations"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#hypothesis-test-1",
    "href": "Projects/stat140/Stat140.html#hypothesis-test-1",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Hypothesis Test 1",
    "text": "Hypothesis Test 1\n\\[\n\\begin{aligned}\nH_{0}: &\\ \\text{Drone strikes have the same civilian impact in Somalia and Yemen.} \\\\\nH_{1}: &\\ \\text{Drone strikes have different civilian impacts across the two regions.}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#hypothesis-test-2",
    "href": "Projects/stat140/Stat140.html#hypothesis-test-2",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Hypothesis Test 2",
    "text": "Hypothesis Test 2"
  },
  {
    "objectID": "Projects/stat140/Stat140.html#hypothesis-test-3",
    "href": "Projects/stat140/Stat140.html#hypothesis-test-3",
    "title": "How Do the Characteristics and Humanitarian Impacts of U.S. Counterterrorism Strikes Differ Between Somalia and Yemen?",
    "section": "Hypothesis Test 3",
    "text": "Hypothesis Test 3\n\\[\n\\begin{aligned}\nH_{0}: &\\ \\text{Reporting uncertainty does not differ between Somalia and Yemen.} \\\\\nH_{1}: &\\ \\text{Reporting uncertainty differs between Somalia and Yemen.}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "Projects/Mag/Mag.html",
    "href": "Projects/Mag/Mag.html",
    "title": "Magnetic nanocomposites for biomedical applications",
    "section": "",
    "text": "Abstract\n\n\n\n\nTissue engineering and regenerative medicine have solved numerous problems related to the repair and regeneration of damaged organs and tissues arising from aging, illnesses, and injuries. Nanotechnology has further aided tissue regeneration science and has provided outstanding opportunities to help disease diagnosis as well as treat damaged tissues. Based on the most recent findings, magnetic nanostructures (MNSs), in particular, have emerged as promising materials for detecting, directing, and supporting tissue regeneration. There have been many reports concerning the role of these nano-building blocks in the regeneration of both soft and hard tissues, but the subject has not been extensively reviewed. Here, we review, classify, and discuss various synthesis strategies for novel MNSs used in medicine. Advanced applications of magnetic nanocomposites (MG-NCs), specifically magnetic nanostructures, are further systematically reviewed. In addition, the scientific and technical aspects of MG-NC used in medicine are discussed considering the requirements for the field. In summary, this review highlights the numerous opportunities and challenges associated with the use of MG-NCs as smart nanocomposites (NCs) in tissue engineering and regenerative medicine.\n\n\n\n\n\n\n\n View Published Article"
  },
  {
    "objectID": "Projects/Education/Education.html",
    "href": "Projects/Education/Education.html",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "",
    "text": "NoteScan Me"
  },
  {
    "objectID": "Projects/Education/Education.html#literature",
    "href": "Projects/Education/Education.html#literature",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "Literature",
    "text": "Literature\n\n\n\n\nExisting literature on teacher pay reveals a strong consensus that teacher pay disparities are both real and significant. Multiple studies documented that teachers earn 14% less than comparably educated professionals (Allegretto et al.) and low compensation harms teacher retention and recruitment. There is also agreement within the literature that school finance structures can impact teacher pay inequities, with property wealth–dependent funding systems advantaging wealthy districts while disadvantaging high-poverty areas (Baker & Weber, Brunner et al., Roza & Miles). Emerging evidence supports that school funding reforms can increase teacher salaries, though these benefits may take up to a decade to materialize (Nguyen et al., Jackson & Morgan). However, contradictions remain regarding whether increased funding automatically equates to higher teacher pay, as Haskinsworth-Lutzow & Rose found that even large revenue infusions to high-poverty districts did not lead to salary increases beyond recession recovery levels. Currently, limited research focuses on the relationship between teacher pay and education quality, with only García & Han demonstrating a positive correlation between higher teacher base salaries and student performance in math and English assessments.\n\n\n\n\n  A classroom in the Navajo Nation."
  },
  {
    "objectID": "Projects/Education/Education.html#which-u.s.-regions-have-the-highest-and-lowest-median-household-incomes-for-families-with-public-school-children",
    "href": "Projects/Education/Education.html#which-u.s.-regions-have-the-highest-and-lowest-median-household-incomes-for-families-with-public-school-children",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "Which U.S. regions have the highest and lowest median household incomes for families with public school children?",
    "text": "Which U.S. regions have the highest and lowest median household incomes for families with public school children?\n                   \n\n\nWe chose a box plot for this visualization because it clearly highlights median household income, while also revealing outliers and regional patterns across the United States. This is important for our project, as we examine how median household income correlates with state education expenditures and, in turn, student outcomes. The visualization shows that the Northeast has the highest median household income overall, with the Middle Atlantic division (including New York, New Jersey, and Pennsylvania) ranking at the top. In contrast, the South has the lowest median household income, particularly the East South Central division (including Alabama, Kentucky, Mississippi, and Tennessee). These regional disparities underscore how economic conditions vary substantially across the country and help explain differences in educational funding and resources."
  },
  {
    "objectID": "Projects/Education/Education.html#how-did-teacher-salaries-change-across-the-united-states-from-202122-to-202223-and-do-states-with-lower-average-salaries-tend-to-have-higher-percent-increases-in-salary",
    "href": "Projects/Education/Education.html#how-did-teacher-salaries-change-across-the-united-states-from-202122-to-202223-and-do-states-with-lower-average-salaries-tend-to-have-higher-percent-increases-in-salary",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "How did teacher salaries change across the United States from 2021–22 to 2022–23, and do states with lower average salaries tend to have higher percent increases in salary?",
    "text": "How did teacher salaries change across the United States from 2021–22 to 2022–23, and do states with lower average salaries tend to have higher percent increases in salary?"
  },
  {
    "objectID": "Projects/Education/Education.html#how-do-states-differ-in-their-expenditures-for-education",
    "href": "Projects/Education/Education.html#how-do-states-differ-in-their-expenditures-for-education",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "How do states differ in their expenditures for education?",
    "text": "How do states differ in their expenditures for education?\n                   \n\n\nThis chart supports our project by highlighting each state’s public expenditures, which is a foundational factor in understanding educational funding disparities. States with higher total expenditures are not necessarily those with the highest teacher salaries or strongest education outcomes, highlighting that how funds are prioritized, not just how much they have, matters deeply. This visualization helps identify patterns in resource allocation that may correlate with regional trends in teacher pay and student performance. It reinforces the idea that systemic and policy-driven decisions shape public education funding across the U.S., contributing to unequal educational outcomes.\nThis data on regional household income and per state expenditures directly support the thesis by showing how broader economic and policy-driven disparities influence education funding. The Northeast, with the highest median household incomes, tends to allocate more resources toward public education, contributing to higher teacher salaries. In contrast, the South, particularly the East South-Central division, has the lowest household incomes, which correlates with lower public school teacher salaries and reduced education funding overall. This reveals systemic disparities in which students that have a lower median household income may consequently receive lower quality education. These patterns reveal how regional economic conditions can result in systemic inequities due to how states value public education."
  },
  {
    "objectID": "Projects/Education/Education.html#which-state-spent-the-longest-total-time-on-teachersalary-legislation-tasks-between-2019-and-2024",
    "href": "Projects/Education/Education.html#which-state-spent-the-longest-total-time-on-teachersalary-legislation-tasks-between-2019-and-2024",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "Which state spent the longest total time on teacher‐salary legislation tasks between 2019 and 2024?",
    "text": "Which state spent the longest total time on teacher‐salary legislation tasks between 2019 and 2024?\n                   \n\n\n\nThe Gantt chart displays the timeline of key legislative tasks—such as Preliminary Research, Draft Legislation, Committee Hearings, and Implementation Phases—for three states (Alabama, California, and New York). By noting the start and end dates of each task, we see which state took longer overall to enact teacher‐salary reforms. California appears to have some of the longest cumulative task durations, especially during Draft Legislation and Implementation. New York shows extended time spans during Committee Hearings and Review/Evaluation. Alabama has shorter durations in some phases but a lengthy Implementation window into 2024.\nWhy Might These Differences Exist? Legislative Complexity & Stakeholder Input: Longer durations can reflect complex negotiations.\nPolitical & Economic Factors: Multiple committee reviews or separate House/Senate approvals can slow legislation (NEA, 2022). States under fiscal strain might need extra budget hearings, delaying passage.\nMeaning Within the Project Context: Within our project on multi‐year teacher‐salary reforms, this Gantt chart highlights differences in how each state navigated the legislative process. A longer total duration may indicate more complex legislative procedures, prolonged committee debates, or staggered implementation timelines. Conversely, a shorter duration suggests a more streamlined or expedited approach. Understanding these disparities can inform policymakers and education stakeholders about potential bottlenecks or best practices when implementing multi‐year salary reforms."
  },
  {
    "objectID": "Projects/Education/Education.html#does-political-affiliation-correlate-with-education-ranking-and-teacher-salary",
    "href": "Projects/Education/Education.html#does-political-affiliation-correlate-with-education-ranking-and-teacher-salary",
    "title": "EducA+tors: Mapping Public School Funding and Educational Equity in the United States",
    "section": "Does Political Affiliation Correlate with Education Ranking and Teacher Salary?",
    "text": "Does Political Affiliation Correlate with Education Ranking and Teacher Salary?\n                   \n\n\n\nThis chart type was chosen for its clarity in allowing side-by-side comparison of performance disparities, making it easy to observe which states significantly exceed or fall below the national average. Each bar represents the deviation in average score from the national public school score baseline, allowing viewers to quickly identify geographic patterns and performance trends. The visualization shows how academic outcomes vary by state and relates to other financial data on state-level education funding.\nThis visualization relates to our project because performance gaps revealed in this chart suggest that educational outcomes are not solely determined by student ability or local conditions, but are linked to how much and how equitably states invest in their public education systems. States that underperform relative to the national average may also be those offering lower teacher salaries and allocating fewer resources to education overall, reinforcing systemic inequities. By combining salary data with performance metrics, this chart strengthens the argument that funding disparities contribute to uneven educational outcomes nationwide.\nBy comparing the Tableau visualizations of state-by-state teacher salary data and student performance metrics, patterns of the relationship between compensation, retention, and educational outcomes becomes apparent. The data reveals that states investing more in educator pay generally see higher student performance. For example, states like Massachusetts, Connecticut, Minnesota, and New Jersey rank within the top 10 in both teacher salary and average student scores. For each of these states, over 30% of their students are achieving proficiency or higher. These states also tend to experience higher stability and competitive recruitment, which likely contributes to continuing the cycle of having consistent educational quality and student success. On the other hand, states like Mississippi, New Mexico, and West Virginia appear on the lower end of the salary and performance spectrum, with low proficiency rates and average scores more than 10 points below the national average. It is also important to note that there were also some discrepancies found between salary increases and student achievement. For example, although New Mexico implemented a significant percent increase in salary, student scores did not reflect this as their performance did not rank in the top 10. This suggests that improvement in performance is not immediate and likely depends on factors such as how salary increases are impacted by broader systemic changes like training, resources, and school infrastructure. Overall, the data shows a moderate to strong positive trend between salary and performance. On average, higher salaries correlate with better performance from students. For example, there are some outliers like Florida that have relatively low salaries but mid range performance. This can be due to factors like cost of living, teacher-student ratios, and state education policy. Ultimately, supporting the conclusion that teacher salary is heavily correlated with educational performance. The outliers support our thesis that systemic inequities drive how states fund their educational systems, directly impacting student achievement and future success. As a result, if states want to improve student outcomes, they should consider investing more in teacher compensation."
  },
  {
    "objectID": "Projects/Add/Ad.html#section",
    "href": "Projects/Add/Ad.html#section",
    "title": "Advances in electroconductive polymers for biomedical sector: structure and properties",
    "section": "",
    "text": "Abstract\n\nThis review examines the synthesis, properties, and broad-spectrum applications of electroconductive polymers (ECPs), including polyaniline, polypyrrole, polythiophene, polyphenylene, and polyacetylene. These polymers exhibit high electrical conductivity, versatility in fabrication, and compatibility with various functionalization techniques, making them particularly attractive for diverse applications. While ECPs have traditionally been used in sensors, actuators, and energy storage systems, their utility extends much further, most notably to the realm of biomedical applications. The review meticulously explores the synthesis techniques of ECPs, shedding light on both chemical and electrochemical methods, and the pivotal role that dopants and polymerization techniques play in shaping the properties of the resultant polymers. Apart from discussing the conventional applications of ECPs, the review devotes substantial attention to their groundbreaking biomedical applications, like tissue engineering, medical implants, and the creation of interfaces with biological tissues. It also underscores the future trajectory of ECP research, emphasizing the development of innovative materials and fabrication methodologies for more advanced applications. With this holistic analysis of the field, the review seeks to enhance readers’’ understanding of the intrinsic properties, structural complexities, and fabrication nuances of ECPs, and inspire continued research and development in this fascinating and consequential domain of materials science.\n\n View Published Article"
  },
  {
    "objectID": "Courses.html#coursework-completed-and-in-progress",
    "href": "Courses.html#coursework-completed-and-in-progress",
    "title": "Relevant Academic Coursework",
    "section": "Coursework Completed and In-Progress",
    "text": "Coursework Completed and In-Progress\n\nUpper Division and Graduate-Level Mathematics & Statistics Courses\n\n\n\n\n\n\n\n\n\n\nNo.\nCourse (Number & Title)\nTerm\nTextbook Ref\n\n\n\n\n1\nMATH 115A – Linear Algebra\nFall 2024\n[5]\n\n\n2\nSTATS 100A – Introduction to Probability\nFall 2024\n[25], [26]\n\n\n3\nMATH 151A – Applied Numerical Methods\nWinter 2025\n[7]\n\n\n4\nSTATS 100B – Mathematical Statistics\nWinter 2025\n[8]\n\n\n5\nSTATS 101A – Data Analysis & Regression\nWinter 2025\n[9], [10]\n\n\n6\nSTATS 100C – Linear Models\nSpring 2025\n[11], [31]\n\n\n7\nSTATS 101B – Design & Analysis of Experiments\nSpring 2025\n[12]\n\n\n8\nSTATS 102A – Intro to Computational Statistics (R)\nSummer 2025\n[21], [22], [23], [24]\n\n\n9\nMATH 164 – Optimization\nFall 2025\n[13]\n\n\n10\nSTATS 101C – Statistical Models & Data Mining\nFall 2025\n[14]\n\n\n11\nSTATS 102C – Monte Carlo Methods\nFall 2025\n[15]\n\n\n12\nMATH 156 – Machine Learning\nWinter 2026\n[16]\n\n\n13\nMATH 171 – Stochastic Processes\nWinter 2026\n[30]\n\n\n14\nSTATS 102B – Computation & Optimization for Statistics\nSpring 2026\n[18]\n\n\n15\nMATH 182 – Algorithms\nSpring 2026\n[29]"
  },
  {
    "objectID": "Courses.html#lower-division-mathematics-statistics-courses",
    "href": "Courses.html#lower-division-mathematics-statistics-courses",
    "title": "Relevant Academic Coursework",
    "section": "Lower Division Mathematics & Statistics Courses",
    "text": "Lower Division Mathematics & Statistics Courses\n\n\n\n\n\n\n\n\n\n\nNo.\nCourse (Number & Title)\nTerm\nTextbook Ref\n\n\n\n\n1\nMATH-227 – Statistics\nWinter 2022\n[27]\n\n\n2\nMATH-229 – Statistics for Data Science\nSummer 2024\n[28]\n\n\n3\nMATH 265 – Calculus I\nWinter 2022\n[1]\n\n\n4\nMATH 266 – Calculus II\nSpring 2022\n[1]\n\n\n5\nMATH 267 – Calculus III\nFall 2022\n[1]\n\n\n6\nMATH 270 – Linear Algebra\nFall 2022\n[2]\n\n\n7\nMATH 272 – Methods of Discrete Mathematics\nFall 2023\n[3]\n\n\n8\nMATH 275 – Ordinary Differential Equations\nSpring 2023\n[4]\n\n\n\n\n\n\n\n\n\n\nNoteShow Textbook References\n\n\n\n\n\nReferences\n[1] Stewart, James. Calculus: Early Transcendentals. 8th ed. Cengage, 2015.\n[2] Larson, Ron. Elementary Linear Algebra. 8th ed. Cengage, 2017.\n[3] Epp, Susanna S. Discrete Mathematics with Applications. 5th ed. Cengage, 2019.\n[4] Zill, Dennis G. A First Course in Differential Equations with Modeling Applications. 11th ed. Cengage, 2018.\n[5] Friedberg, Stephen H., Arnold J. Insel, and Lawrence E. Spence. Linear Algebra. 5th ed. Pearson, 2024.\n[6] Ross, Sheldon M. A First Course in Probability. 10th ed. Pearson, 2019.\n[7] Burden, Richard L., J. Douglas Faires, and Annette M. Burden. Numerical Analysis. 10th ed. Cengage, 2015.\n[8] Rice, John A. Mathematical Statistics and Data Analysis. 3rd ed. Cengage, 2006.\n[9] Sheather, Simon J. A Modern Approach to Regression with R. Springer, 2009.\n[10] Kutner, Michael H., et al. Applied Linear Statistical Models. 5th ed. McGraw-Hill, 2005.\n[11] Abraham, B., and J. Ledolter. Introduction to Regression Modeling. Duxbury, 2006.\n[12] Montgomery, Douglas C. Design and Analysis of Experiments. 9th ed. Wiley, 2017.\n[13] Boyd, Stephen, and Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\n[14] James, Gareth, et al. An Introduction to Statistical Learning with R. 2nd ed., Springer, 2021.\n[15] Robert, Christian P., and George Casella. Introducing Monte Carlo Methods with R. Springer, 2010.\n[16] Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.\n[17] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[18] Zhou, Qing. Course Notes for STATS 102B. UCLA.\n[19] Isaaks, Edward H., and R. Mohan Srivastava. An Introduction to Applied Geostatistics. Oxford UP, 1989.\n[20] UCLA Statistics 100C course handouts.\nhttp://www.stat.ucla.edu/~nchristo/statistics100C/\n[21] Wickham, Hadley. Advanced R. 2nd ed. Chapman & Hall/CRC, 2019.\n[22] Jones, O., R. Maillardet, and A. Robinson. Introduction to Scientific Programming and Simulation Using R. CRC Press, 2009.\n[23] Chang, Winston. R Graphics Cookbook. O’Reilly, 2012.\n[24] Zieffler, Andrew, et al. Comparing Groups Using R. Wiley, 2011.\n[25] DeGroot, Morris H., and Mark J. Schervish. Probability and Statistics. 4th ed. Pearson, 2012.\n[26] Hogg, Robert V., et al. Probability and Statistical Inference. 10th ed. Pearson, 2019.\n[27] Illowsky, Barbara, and Susan Dean. Introductory Statistics. 2nd ed. OpenStax, 2022.\n[28] Adhikari, Ani, et al. Computational and Inferential Thinking. 2nd ed., 2022.\n[29] Kleinberg, Jon, and Éva Tardos. Algorithm Design. Addison-Wesley.\n[30] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[31] UCLA Statistics 100C handouts."
  },
  {
    "objectID": "Courses.html#references",
    "href": "Courses.html#references",
    "title": "Relevant Academic Coursework",
    "section": "References",
    "text": "References\n[1] Stewart, James. Calculus: Early Transcendentals. 8th ed. Cengage, 2015.\n[2] Larson, Ron. Elementary Linear Algebra. 8th ed. Cengage, 2017.\n[3] Epp, Susanna S. Discrete Mathematics with Applications. 5th ed. Cengage, 2019.\n[4] Zill, Dennis G. A First Course in Differential Equations with Modeling Applications. 11th ed. Cengage, 2018.\n[5] Friedberg, Stephen H., Arnold J. Insel, and Lawrence E. Spence. Linear Algebra. 5th ed. Pearson, 2024.\n[6] Ross, Sheldon M. A First Course in Probability. 10th ed. Pearson, 2019.\n[7] Burden, Richard L., J. Douglas Faires, and Annette M. Burden. Numerical Analysis. 10th ed. Cengage, 2015.\n[8] Rice, John A. Mathematical Statistics and Data Analysis. 3rd ed. Cengage, 2006.\n[9] Sheather, Simon J. A Modern Approach to Regression with R. Springer, 2009.\n[10] Kutner, Michael H., et al. Applied Linear Statistical Models. 5th ed. McGraw-Hill, 2005.\n[11] Abraham, B., and J. Ledolter. Introduction to Regression Modeling. Duxbury, 2006.\n[12] Montgomery, Douglas C. Design and Analysis of Experiments. 9th ed. Wiley, 2017.\n[13] Boyd, Stephen, and Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\n[14] James, Gareth, et al. An Introduction to Statistical Learning with R. 2nd ed., Springer, 2021.\n[15] Robert, Christian P., and George Casella. Introducing Monte Carlo Methods with R. Springer, 2010.\n[16] Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.\n[17] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[18] Zhou, Qing. Course Notes for STATS 102B. UCLA.\n[19] Isaaks, Edward H., and R. Mohan Srivastava. An Introduction to Applied Geostatistics. Oxford UP, 1989.\n[20] UCLA Statistics 100C course handouts.\nhttp://www.stat.ucla.edu/~nchristo/statistics100C/\n[21] Wickham, Hadley. Advanced R. 2nd ed. Chapman & Hall/CRC, 2019.\n[22] Jones, O., R. Maillardet, and A. Robinson. Introduction to Scientific Programming and Simulation Using R. CRC Press, 2009.\n[23] Chang, Winston. R Graphics Cookbook. O’Reilly, 2012.\n[24] Zieffler, Andrew, et al. Comparing Groups Using R. Wiley, 2011.\n[25] DeGroot, Morris H., and Mark J. Schervish. Probability and Statistics. 4th ed. Pearson, 2012.\n[26] Hogg, Robert V., et al. Probability and Statistical Inference. 10th ed. Pearson, 2019.\n[27] Illowsky, Barbara, and Susan Dean. Introductory Statistics. 2nd ed. OpenStax, 2022.\n[28] Adhikari, Ani, et al. Computational and Inferential Thinking. 2nd ed., 2022.\n[29] Kleinberg, Jon, and Éva Tardos. Algorithm Design. Addison-Wesley.\n[30] Durrett, Rick. Essentials of Stochastic Processes. 2nd ed. Springer, 2012.\n[31] UCLA Statistics 100C handouts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Abou",
    "section": "",
    "text": "About this site\n\n1 + 778\n\n[1] 779\n\n\n\nrunif(100)\n\n  [1] 0.119809215 0.702263172 0.264996174 0.630579249 0.917529952 0.232652186\n  [7] 0.518482357 0.163793104 0.783290996 0.688269334 0.880113486 0.361883655\n [13] 0.563803916 0.607674709 0.696025274 0.402228080 0.165349862 0.751654092\n [19] 0.002632787 0.348466842 0.327226867 0.625708770 0.137678662 0.023899324\n [25] 0.069478603 0.447974506 0.233826007 0.721954083 0.091949725 0.800129639\n [31] 0.239818224 0.192982953 0.744614812 0.435613604 0.705823205 0.318297446\n [37] 0.365020782 0.137437444 0.707091527 0.049867812 0.203683515 0.313231578\n [43] 0.649590572 0.217318694 0.299635907 0.828468723 0.352362481 0.683364950\n [49] 0.335869826 0.165775567 0.234657520 0.038281642 0.404482291 0.576648100\n [55] 0.678910343 0.092911049 0.167563125 0.782019468 0.518592852 0.151298093\n [61] 0.897935863 0.223629006 0.897684842 0.795080786 0.366497229 0.100565562\n [67] 0.881799398 0.898571128 0.500289764 0.026730901 0.163269650 0.312415584\n [73] 0.630289461 0.837167470 0.651520834 0.796403639 0.801805124 0.752599408\n [79] 0.369531703 0.689206148 0.499856126 0.289179444 0.853814665 0.763107007\n [85] 0.404323525 0.125685660 0.160300118 0.390467844 0.916437768 0.587550690\n [91] 0.698513467 0.148460445 0.631001519 0.862905346 0.936776087 0.349843704\n [97] 0.314392901 0.214418409 0.842032111 0.936743572\n\n\n\nset.seed(123)\nplot(1:20, runif(20))\n\n\n\n\n\n\n\n\n\nplot(1:40,runif(40))\n\n\n\n\n\n\n\n\n\nx &lt;- seq(0, 2*pi, length.out = 100)  # 100 points from 0 to 2π\ny &lt;- sin(x)                          # sine of each x\nplot(x, y, type = \"l\")               # 'l' means line plot\n\n\n\n\n\n\n\nplot(x, y, \n     type = \"l\", \n     col = \"blue\", \n     lwd = 2,\n     main = \"Plot of sin(x)\",\n     xlab = \"x (radians)\",\n     ylab = \"sin(x)\")\nlines(x, cos(x), col = \"red\", lwd = 2)\nlegend(\"topright\", legend = c(\"sin(x)\", \"cos(x)\"),\n       col = c(\"blue\", \"red\"), lwd = 2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Keivan Bolouri",
    "section": "",
    "text": "Welcome to my page!"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Keivan Bolouri",
    "section": "About me",
    "text": "About me\nHello! My name is Keivan Bolouri. I am passionate about technology, data, and continuous learning.\nI enjoy building projects, exploring new tools, and applying what I learn to real-world problems."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Keivan Bolouri",
    "section": "Education",
    "text": "Education\n\nUniversity of California, Los Angeles (UCLA)\n\nI’m currently pursuing a B.S. in Statistics and Data Science at UCLA, where I focus on turning complex data into clear, actionable insights. Alongside core training in statistical modeling and algorithmic thinking, I’m especially interested in statistical genetics and computational biology—fields that let me explore how data can reveal the patterns and mechanisms behind biological systems.\n\n\n\nOutside of academics, I enjoy hiking, running, and staying active outdoors.\nFeel free to explore my links above to learn more about my work and interests. ✨"
  },
  {
    "objectID": "Projects/CellTypes/CellTypes.html#section",
    "href": "Projects/CellTypes/CellTypes.html#section",
    "title": "Cell Types: Origin and Function",
    "section": "",
    "text": "Abstract\n\n\n\nCells are essential components of biological systems and are involved in various activities, such as interacting with the surrounding environment. Researchers are taking advantage of naturally derived cell membranes to enhance the bio-interfacing capabilities of nanoparticles. The use of cell membrane-coating technology represents an exciting breakthrough in the field of nanomedicine. This technique has the potential to enhance the ability of nanoparticles to interact with biological systems and deliver drugs or therapeutic agents more effectively in clinical settings. This chapter provides a comprehensive overview of the different types of cells used for membrane coating of nanoparticles, including red blood cells, platelets, white blood cells, stem cells, cancer cells, hybrid cells, and other specialized cell types like beta cells, endothelial cells, fibroblast cells, and bacterial cells. The chapter delves into the origin and function of each of these cell types and highlights the potential applications of cell membrane-coating technology for each.\n\n View Book Chapter"
  },
  {
    "objectID": "Projects/Harness/Harness.html",
    "href": "Projects/Harness/Harness.html",
    "title": "Harnessing the Power of Electroconductive Polymers for Breakthroughs in Tissue Engineering and Regenerative Medicine",
    "section": "",
    "text": "Abstract\n\nElectroconductive polymers (ECPs) have garnered increasing attention in the realms of tissue engineering and regenerative medicine due to their unique physicochemical properties, including their ability to conduct electrical signals. These polymers, with inherent conductivity mirroring that of native tissues, present a promising platform for scaffolds that can modulate cell behavior and tissue formation through electrical stimulation. The biocompatibility, tunable conductivity, and topographical features of ECPs enhance cellular adhesion, proliferation, and differentiation. Furthermore, their electrical properties have been shown to augment nerve regeneration, cardiac tissue repair, and musculoskeletal tissue formation. Combined with other biomaterials or biological molecules, ECP-based composites exhibit synergistic effects, promoting enhanced tissue regeneration. Moreover, the integration of ECPs with cutting-edge technologies such as 3D printing and microfluidics propels the design of sophisticated constructs for tissue engineering applications. This paper concludes with the challenges faced in the clinical translation of ECP-based scaffolds and provides perspectives on the future trajectory of ECPs in regenerative medicine. The synthesis of ECPs with emerging biotechnologies has the potential to revolutionize treatments, bridging the gap between traditional regenerative approaches and sophisticated bioelectronic remedies.\n\n View Published Article"
  },
  {
    "objectID": "Projects/Metal/Metal.html",
    "href": "Projects/Metal/Metal.html",
    "title": "Metal-Organic Frameworks in Bone Regeneration",
    "section": "",
    "text": "Abstract\n\nThe occurrence of traumatic bone defects caused by accidents, diseases, and surgeries has become increasingly common. Consequently, there has been a noticeable increase in the overall number of bone defects reported. Treating bone defects is characterized by long treatment periods, high costs, and unpredictable outcomes, often accompanied by complications like infections and bone discontinuity. Consequently, this situation significantly impacts the physical, mental, and financial well-being of patients and poses a challenge to orthopedic surgeons. This has piqued a considerable interest in the realm of bone therapy and repair. Materials other than autogenous bone have not yet achieved the ability to offer ideal biocompatibility, osteogenesis, osteoconductivity, and osteoinduction properties simultaneously. Moreover, the scarcity of autologous bone sources has necessitated the search for new replacement materials. Metal-organic frameworks (MOFs) represent a novel class of functional materials that have gained extensive attention in the biomedical field in recent years. This is attributed to their porous nature, large specific surface area, tailorable chemistry, and their potential for drug loading. As bone treatment and repair research progresses, more investigators are exploring the potential of using MOFs for bone therapy and repair applications. Taking all these aspects into account, this chapter summarizes the current utilization of MOFs in bone therapy and regeneration, while also providing an outlook on the potential prospects of MOFs in this field.\n:::: ::: text-justify Literature Existing literature on teacher pay reveals a strong consensus that teacher pay disparities are both real and significant. Multiple studies documented that teachers earn 14% less than comparably educated professionals (Allegretto et al.) and low compensation harms teacher retention and recruitment. There is also agreement within the literature that school finance structures can impact teacher pay inequities, with property wealth dependent funding systems advantaging wealthy districts while disadvantaging high poverty areas (Baker & Weber, Brunner et al., Roza & Miles). Emerging evidence supports that school funding reforms can increase teacher salaries, though these benefits may take up to a decade to materialize (Nguyen et al., Jackson & Morgan). However, there are contradictions regarding whether increased funding automatically equates to higher teacher pay, as Hawksworth-Lutzow & Rose found that even large revenue infusions to high-poverty districts didn’t lead to salary increases beyond recession recovery levels. Currently, limited research focuses on the relationship between teacher pay and education quality, with only García & Han demonstrating a positive correlation between higher teacher base salaries and student performance in math and English assessments. This leaves questions around the extent to which teacher compensation and education quality are correlated. ::: \n View Book Chapter"
  },
  {
    "objectID": "Projects/SkinCancer/SkinCancer.html",
    "href": "Projects/SkinCancer/SkinCancer.html",
    "title": "Predicting Skin Cancer Using Statistical Learning Models",
    "section": "",
    "text": "⬇ Download PDF"
  },
  {
    "objectID": "Projects/SkinCancer/SkinCancer.html#exploratory-data-analysis",
    "href": "Projects/SkinCancer/SkinCancer.html#exploratory-data-analysis",
    "title": "Predicting Skin Cancer Using Statistical Learning Models",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nWe began by examining the overall structure and distributions in the training dataset. The response variable (Cancer) is binary (Benign or Malignant), and we observed a slight class imbalance: benign lesions were more frequent than malignant lesions in the training data. This imbalance means that a naive classifier that predicts all cases as benign would achieve a non-trivial accuracy, so careful model evaluation is necessary. We also inspected the distribution of key predictors. For example, the average age of patients with malignant lesions appeared higher than that of patients with benign lesions, consistent with the fact that skin cancer risk increases with age. We explored categorical risk factors as well: certain exposure-related factors (such as indicators of high UV exposure or tanning habits) were somewhat more prevalent in malignant cases, though there was significant overlap between the benign and malignant groups for most individual predictors. Overall, no single predictor showed a dramatic separation between malignant and benign lesions in isolation, suggesting that multiple factors in combination would be needed for effective prediction. In addition, we checked for missing data and outliers during the exploratory phase. We found that the dataset’s overall quality was high, with only a moderate amount of missing values (on the order of 7–8% missing per predictor). There was no evidence of extreme outliers that would require removal or transformation beyond standardization. The presence of some missing values and the lack of obvious one-variable predictors of cancer underlined the need for a robust modeling approach with proper data preprocessing, which we implemented as described below.\n\n\n\n\n\nCancer Type\nNumber of Samples\n\n\n\n\nBenign\n23868\n\n\nMalignant\n26132"
  },
  {
    "objectID": "Projects/SkinCancer/SkinCancer.html#data-cleaning-and-missing-values",
    "href": "Projects/SkinCancer/SkinCancer.html#data-cleaning-and-missing-values",
    "title": "Predicting Skin Cancer Using Statistical Learning Models",
    "section": "Data Cleaning and Missing Values",
    "text": "Data Cleaning and Missing Values\nAfter completing the exploratory analysis, we examined the dataset for missing values. We found that the overall data quality was relatively high, with most predictors containing approximately 7–8% missing values. No predictor exceeded 10% missingness, so eliminating variables or observations would have resulted in unnecessary data loss. To address missing values in a consistent manner, we applied the following imputation strategy: Numerical variables were imputed using the median, which is robust to outliers. Categorical variables were imputed using the most frequent category (mode). This approach allowed us to preserve all 50,000 observations in the training dataset while ensuring that the data were suitable for modeling. After imputation, no missing values remained in the predictors used for analysis.\n\n\nzeroGrob[NULL] \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 1: Top ten variables with the highest proportion of missing values.\n\n\n\n\n\n\n\n\nVariable\nMissing (%)\n\n\n\n\nvitamin_d_supplement\n8.3\n\n\nphone_brand\n8.2\n\n\nskin_tone\n8.2\n\n\nsunscreen_spf\n8.2\n\n\npreferred_shoe_type\n8.2\n\n\nsunscreen_freq\n8.2\n\n\nresidence_lat\n8.2\n\n\ncommute_minutes\n8.1\n\n\nnear_high_power_cables\n8.1\n\n\nincome\n8.1\n\n\n\n (a) Training set variables.\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMissing (%)\n\n\n\n\nresidence_lon\n8.5\n\n\nphone_brand\n8.4\n\n\npreferred_shoe_type\n8.3\n\n\nuses_smartwatch\n8.3\n\n\nskin_tone\n8.3\n\n\nsmoking_status\n8.2\n\n\nincome\n8.2\n\n\nnear_high_power_cables\n8.2\n\n\nlesion_color\n8.2\n\n\nskin_photosensitivity\n8.1\n\n\n\n (b) Test set variables.\n\n\n\n\n\n\n\n\n\n\n\nUsing these association measures, all predictors were ranked from strongest to weakest. Variables with very weak association to the response variable were discarded, while stronger predictors were retained. This process reduced the dataset from 51 variables to 35 total variables, including the response variable. The final set consisted of 20 numerical predictors and 14 categorical predictors, while maintaining all original observations. This variable selection process helped simplify the modeling stage, reduced multicollinearity, and improved model interpretability, while retaining the most informative predictors for classification."
  },
  {
    "objectID": "Projects/SkinCancer/SkinCancer.html#variable-selection",
    "href": "Projects/SkinCancer/SkinCancer.html#variable-selection",
    "title": "Predicting Skin Cancer Using Statistical Learning Models",
    "section": "Variable Selection",
    "text": "Variable Selection\nGiven the large number of predictors, variable selection was necessary to reduce dimensionality and eliminate weak predictors that could introduce noise and increase the risk of overfitting. For categorical predictors, we used Cramér’s V to measure the strength of association between each categorical variable and the cancer outcome. Cramér’s V is based on the chi-squared statistic and produces values between 0 and 1, with larger values indicating stronger association. Here is a sample of the first 10 variables: For numerical predictors, we computed the point-biserial correlation, which measures the strength of association between a continuous predictor and a binary response variable. Numerical variables were ranked based on the absolute value of this correlation.\n\n\n\nTop 10 Categorical Predictors Ranked by Cramér’s V (Training Data)\n\n\nVariable\nCramér’s V\n\n\n\n\nfamily_history\n0.104\n\n\nskin_tone\n0.087\n\n\nsunscreen_freq\n0.066\n\n\nimmunosuppressed\n0.060\n\n\noccupation\n0.045\n\n\ntanning_bed_use\n0.041\n\n\nclothing_protection\n0.036\n\n\nskin_photosensitivity\n0.033\n\n\nhat_use\n0.028\n\n\nlesion_location\n0.011\n\n\n\n\n\n\nTop 10 Numerical Predictors Ranked by Point-Biserial Correlation (Training Data)\n\n\nVariable\nPoint-Biserial Correlation\n\n\n\n\nage\n0.1355\n\n\navg_daily_uv\n0.0599\n\n\nnumber_of_lesions\n0.0513\n\n\nsunburns_last_year\n0.0457\n\n\noutdoor_job\n0.0451\n\n\nlesion_size_mm\n0.0223\n\n\nsunscreen_spf\n-0.0174\n\n\nyears_lived_at_address\n0.0103\n\n\nincome\n0.0088\n\n\ndesk_height_cm\n0.0083\n\n\n\n\n\n[1] 35\n\n\n\n\n\n\nFinal Selected Predictors After Association-Based Variable Screening\n\n\nNo\nType\nVariable\nSelection Criterion\n\n\n\n\n1\nCategorical\nfamily_history\nCramér’s V &gt; 0.05\n\n\n2\nCategorical\nskin_tone\nCramér’s V &gt; 0.05\n\n\n3\nCategorical\nsunscreen_freq\nCramér’s V &gt; 0.05\n\n\n4\nCategorical\nimmunosuppressed\nCramér’s V &gt; 0.05\n\n\n5\nCategorical\noccupation\nCramér’s V &gt; 0.05\n\n\n6\nCategorical\ntanning_bed_use\nCramér’s V &gt; 0.05\n\n\n7\nCategorical\nclothing_protection\nCramér’s V &gt; 0.05\n\n\n8\nCategorical\nskin_photosensitivity\nCramér’s V &gt; 0.05\n\n\n9\nCategorical\nhat_use\nCramér’s V &gt; 0.05\n\n\n10\nCategorical\nlesion_location\nCramér’s V &gt; 0.05\n\n\n11\nCategorical\nfavorite_cuisine\nCramér’s V &gt; 0.05\n\n\n12\nCategorical\nmusic_genre\nCramér’s V &gt; 0.05\n\n\n13\nCategorical\nlesion_color\nCramér’s V &gt; 0.05\n\n\n14\nCategorical\nsunscreen_brand\nCramér’s V &gt; 0.05\n\n\n1\nNumerical\nage\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n2\nNumerical\navg_daily_uv\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n3\nNumerical\nnumber_of_lesions\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n4\nNumerical\nsunburns_last_year\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n5\nNumerical\noutdoor_job\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n6\nNumerical\nlesion_size_mm\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n7\nNumerical\nsunscreen_spf\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n8\nNumerical\nyears_lived_at_address\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n9\nNumerical\nincome\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n10\nNumerical\ndesk_height_cm\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n11\nNumerical\nresidence_lon\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n12\nNumerical\nexercise_freq_per_week\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n13\nNumerical\nzip_code_last_digit\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n14\nNumerical\ndistance_from_beach_km\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n15\nNumerical\nalcohol_drinks_per_week\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n16\nNumerical\nBMI\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n17\nNumerical\ncommute_minutes\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n18\nNumerical\nfrequency_doctor_visits_per_year\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n19\nNumerical\nresidence_lat\nAbs. Point-Biserial Corr. &gt; 0.02\n\n\n20\nNumerical\nmonthly_screen_time_minutes\nAbs. Point-Biserial Corr. &gt; 0.02"
  }
]